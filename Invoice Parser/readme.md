# Creating Custom Parser 

In this project we see how we can create a custom parser which DA uses for it's extraction

We have used AWS-textractor as a third party parser for this demo

# Pre-requisites to run the bot
* Minimum v29 Control room
* IQBot admin role in the same control room
* AWS account with textract access.
* AWS secret key and access key.
* Postman

#### Step 1:
* Go to the console and create an IAM profile for yourself 
* In the permission policies, grant access to AmazonS3FullAccess, AmazonTextractFullAccess
<img width="960" alt="amaz1" src="https://github.com/hasnainsyed73/RPA/assets/129178965/351c45cf-a601-46c6-8a6d-6a0de977b730">

#### Step 2:
* Go to Security credentials
* Create your credentials(secret key and access key)

#### Step 3:
* Download the project to local and and add the access key and secret key that you've generated in AWSConnect class.
<img width="638" alt="amaz2" src="https://github.com/hasnainsyed73/RPA/assets/129178965/c2584e2b-63d2-4214-9d86-21ec60c36b14">


#### Step 4:
* After the code configuration is done and code setup is completed. Build the project, use command "gradlew.bat clean build shadowJar".
* You can find a jar compiled in the project/build/libs folder.
* Upload this jar to the control room and test the jar in a bot.

#### Step 5:

* Open Postman to post the following API's

* Endpoint: control-room-url/cognitive/v3/parsers
* Method: Post
* Headers: X-Authorization
* Use the below params in the body
<img width="617" alt="amaz3" src="https://github.com/hasnainsyed73/RPA/assets/129178965/e74d5a59-7703-4d63-8557-727945302e74">


#### Step 6:

#### To get the parser-id

* Endpoint: control-room-url/cognitive/v3/parsers
* Method: Get
* Headers: X-Authorization
* Copy the parser id from the response json for your parser.

#### Step 7:

#### To get domainLanguageId, domainId,domainName, domainLanguageProviderId, domainLanguageProviderParserId

* Paste the parser id in this endpoint
* Endpoint: control-room-url/cognitive/v3/parsers/<parser-id>
* Method: Get
* Headers: X-Authorization
* Copy the domainLanguageId,domainId,domainName,domainLanguageProviderId,domainLanguageProviderParserId from the response json for your parser.

#### Step 8:

#### To post this on the learning instance page.

* Endpoint: control-room-url/cognitive/v3/learninginstances
* Method: Post
* Headers: X-Authorization
* Replace domainLanguageId,domainId,domainName,domainLanguageProviderId,domainLanguageProviderParserId in the body with your copied values.
* Add more fields in the body in the same format if you want to include some more fields for extraction
* Body: {
    "locale": "en-US",
    "isHeuristicFeedbackEnabled": false,
    "name": "Amazon-provider-30",
    "isExternal": false,
    "ocrEngineId": "",
    "modelId": "",
    "modelApiVersion": "",
    "domainLanguageId": "B62EFA19-3592-4D2B-910A-E9C1C7DAE1A9",
    "domainId": "E3B56181-35BF-4B22-B0E8-83400FF066D6",
    "domainName": "Invoice 31",
    "domainLanguageProviderId": "8083C0FE-C2B9-4A76-AD14-C34382F9E6C9",
    "domainLanguageProviderParserId": "48E74B04-3DAD-4D07-9B1F-E78BAF98F511",
    "fields": [
         {
            "domainObjectId": null,
            "name": "invoice_date",
            "description": "",
            "confidenceThreshold": 80,
            "isRequired": true,
            "defaultAliases": [],
            "customAliases": [],
            "fieldRules": [],
            "isCustom": true,
            "dataType": "DATE",
            "domainVersion": "",
            "featureType": "KEY_VALUE",
            "displayName": "invoice_date",
            "isEnabled": true,
            "isNormalizationEnabled": false,
            "normalizationFormat": ""
        }
    ],
    "tables": [
        {
            "name": "table",
            "description": "",
            "tableHeaders": []
        }
    ]
}

#### Step 7:
* Open the learning instance page when you try to create new learning instance and click on document type you'll be able to see the new document that you've posted.
* And when you click on the parser, you'll be able to find your new parser.

#### The AWS-textractor works for images type for this configuration, we need to do extra configurations to include the other document types.

### Flow of code
* The entry point of the code is compute method in ExtractionCommand class where we upload the file.
* The AWS textract generates a json when the file is uploaded for extraction.
* The Document Automation backend uses a JSON to process and download the extraction result for the document.
* The metadata of the json which is generated by AWS-textract and the metadata which is required by DA is not the same. In order to match them we've written different code in different classes.
* Prominently we have used a library called JOLT to transform the data. The code can be seen in the "DATreansformation" class in the src code.
* We can see another class called "MakingList" in the src code which is being used to reformat the json after it is processed by JOLT.
* ExtractionCommand-->MakingList-->DATreansformation-->TextractCoordinatesConverter-->AWSConnect
 



 


